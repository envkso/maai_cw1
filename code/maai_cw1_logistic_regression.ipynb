{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "from sklearn.utils.validation import column_or_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDUCE_FEATURES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptDir = os.getcwd() # Assumes that script is executed from its actual location\n",
    "relPath = r\"../output/\"\n",
    "XtrainFilePath = os.path.join(scriptDir, relPath, \"X_train_pp.csv\")\n",
    "ytrainFilePath = os.path.join(scriptDir, relPath, \"y_train.csv\")\n",
    "XvalFilePath = os.path.join(scriptDir, relPath, \"X_val_pp.csv\")\n",
    "yvalFilePath = os.path.join(scriptDir, relPath, \"y_val.csv\")\n",
    "XtestFilePath = os.path.join(scriptDir, relPath, \"X_test_pp.csv\")\n",
    "columnsNamesPath = os.path.join(scriptDir, relPath, \"column_names.csv\")\n",
    "selectedColumnsNamesPath = os.path.join(scriptDir, relPath, \"selectedColumns_Lasso.csv\")\n",
    "\n",
    "relPathOutput = r\"../output/\"\n",
    "outputFolderPath = os.path.join(scriptDir, relPathOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.read_csv(columnsNamesPath,header=None)\n",
    "columns = list(columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features\n",
    "X_train = pd.read_csv(XtrainFilePath, delimiter=',',header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2430981, 177)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dimensions as expected\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REDUCE_FEATURES:\n",
    "    selectedColumns = pd.read_csv(selectedColumnsNamesPath,header=None)\n",
    "    selectedColumns = list(selectedColumns[0])\n",
    "    X_train = X_train[selectedColumns]\n",
    "    print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels\n",
    "y_train = pd.read_csv(ytrainFilePath, delimiter=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "clf = LogisticRegression(solver='liblinear').fit(X_train, y_train[0].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL\n",
    "#dump(clf, r\"../output/logRes_3_liblinear_l2_20190228.joblib\")\n",
    "#clf = load(r\"../output/logRes_3_liblinear_l2_20190228.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params() # check params of loaded model, confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on the training data\n",
    "predictions = clf.predict(X_train)\n",
    "predictionProb = clf.predict_proba(X_train) # note this gives probability for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796.1144707583194"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictionProb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992484515510405 0.5027795658962866 0.18518518518518517 0.005577244841048522 0.010828370330265295 2429144 44 1783 10 0.5027795658962865\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_train, predictions)\n",
    "bAccuracy = balanced_accuracy_score(y_train, predictions)\n",
    "precision = precision_score(y_train, predictions)\n",
    "recall = recall_score(y_train, predictions)\n",
    "f1 = f1_score(y_train, predictions)\n",
    "tn, fp, fn, tp = np.reshape(confusion_matrix(y_train, predictions), (4,))\n",
    "rocAuc = roc_auc_score(y_train, predictions)\n",
    "print(accuracy, bAccuracy, precision, recall, f1, tn, fp, fn, tp, rocAuc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prc = precision_recall_curve(y_sample, predictionProb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on the validation data\n",
    "X_val = pd.read_csv(XvalFilePath, delimiter=',',header=None, names=columns)\n",
    "y_val = pd.read_csv(yvalFilePath, delimiter=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REDUCE_FEATURES:\n",
    "    X_val = X_val[selectedColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_val)\n",
    "predictionProb = clf.predict_proba(X_val) # note this gives probability for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993254914863865 0.5024686625772838 0.2 0.0049504950495049506 0.00966183574879227 303719 4 201 1 0.5024686625772838\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_val, predictions)\n",
    "bAccuracy = balanced_accuracy_score(y_val, predictions)\n",
    "precision = precision_score(y_val, predictions)\n",
    "recall = recall_score(y_val, predictions)\n",
    "f1 = f1_score(y_val, predictions)\n",
    "tn, fp, fn, tp = np.reshape(confusion_matrix(y_val, predictions), (4,))\n",
    "rocAuc = roc_auc_score(y_val, predictions)\n",
    "print(accuracy, bAccuracy, precision, recall, f1, tn, fp, fn, tp, rocAuc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce probabilities for the testing set\n",
    "X_test = pd.read_csv(XtestFilePath, delimiter=',',header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REDUCE_FEATURES:\n",
    "    X_test = X_test[selectedColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "predictionProb = clf.predict_proba(X_test) # note this gives probability for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(r\"../output/logRes_3_liblinear_l2_20190228_OUT.csv\", predictionProb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
