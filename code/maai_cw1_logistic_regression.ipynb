{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "from sklearn.utils.validation import column_or_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDUCE_FEATURES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scriptDir = os.getcwd() # Assumes that script is executed from its actual location\n",
    "relPath = r\"../output/\"\n",
    "XtrainFilePath = os.path.join(scriptDir, relPath, \"X_train_pp.csv\")\n",
    "ytrainFilePath = os.path.join(scriptDir, relPath, \"y_train.csv\")\n",
    "XvalFilePath = os.path.join(scriptDir, relPath, \"X_val_pp.csv\")\n",
    "yvalFilePath = os.path.join(scriptDir, relPath, \"y_val.csv\")\n",
    "XtestFilePath = os.path.join(scriptDir, relPath, \"X_test_pp.csv\")\n",
    "columnsNamesPath = os.path.join(scriptDir, relPath, \"column_names.csv\")\n",
    "selectedColumnsNamesPath = os.path.join(scriptDir, relPath, \"selectedColumns_Lasso.csv\")\n",
    "\n",
    "relPathOutput = r\"../output/\"\n",
    "outputFolderPath = os.path.join(scriptDir, relPathOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.read_csv(columnsNamesPath,header=None)\n",
    "columns = list(columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features\n",
    "X_train = pd.read_csv(XtrainFilePath, delimiter=',',header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2430981, 547)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dimensions as expected\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2430981, 232)\n"
     ]
    }
   ],
   "source": [
    "if REDUCE_FEATURES:\n",
    "    selectedColumns = pd.read_csv(selectedColumnsNamesPath,header=None)\n",
    "    selectedColumns = list(selectedColumns[0])\n",
    "    X_train = X_train[selectedColumns]\n",
    "    print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels\n",
    "y_train = pd.read_csv(ytrainFilePath, delimiter=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "clf = LogisticRegression(solver='liblinear').fit(X_train, y_train[0].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../output/logRes_3_liblinear_l2_20190228.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAVE MODEL\n",
    "dump(clf, r\"../output/logRes_3_liblinear_l2_20190228.joblib\")\n",
    "# clf = load(r\"../output/xxxxx.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params() # check params of loaded model, confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on the training data\n",
    "predictions = clf.predict(X_train)\n",
    "predictionProb = clf.predict_proba(X_train) # note this gives probability for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1796.3274053174553"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictionProb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9992472174813378 0.5025002919940414 0.16363636363636364 0.0050195203569436695 0.009740259740259738 2429142 46 1784 9\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_train, predictions)\n",
    "bAccuracy = balanced_accuracy_score(y_train, predictions)\n",
    "precision = precision_score(y_train, predictions)\n",
    "recall = recall_score(y_train, predictions)\n",
    "f1 = f1_score(y_train, predictions)\n",
    "tn, fp, fn, tp = np.reshape(confusion_matrix(y_train, predictions), (4,))\n",
    "print(accuracy, bAccuracy, precision, recall, f1, tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prc = precision_recall_curve(y_sample, predictionProb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on the validation data\n",
    "X_val = pd.read_csv(XvalFilePath, delimiter=',',header=None, names=columns)\n",
    "y_val = pd.read_csv(yvalFilePath, delimiter=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REDUCE_FEATURES:\n",
    "    X_val = X_val[selectedColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_val)\n",
    "predictionProb = clf.predict_proba(X_val) # note this gives probability for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\Anaconda2\\envs\\py3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\matth\\Anaconda2\\envs\\py3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993353623426833 0.5 0.0 0.0 0.0 303723 0 202 0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_val, predictions)\n",
    "bAccuracy = balanced_accuracy_score(y_val, predictions)\n",
    "precision = precision_score(y_val, predictions)\n",
    "recall = recall_score(y_val, predictions)\n",
    "f1 = f1_score(y_val, predictions)\n",
    "tn, fp, fn, tp = np.reshape(confusion_matrix(y_val, predictions), (4,))\n",
    "print(accuracy, bAccuracy, precision, recall, f1, tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce probabilities for the testing set\n",
    "X_test = pd.read_csv(XtestFilePath, delimiter=',',header=None, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REDUCE_FEATURES:\n",
    "    X_test = X_test[selectedColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "predictionProb = clf.predict_proba(X_test) # note this gives probability for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(r\"../output/logRes_3_liblinear_l2_20190228_OUT.csv\", predictionProb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
